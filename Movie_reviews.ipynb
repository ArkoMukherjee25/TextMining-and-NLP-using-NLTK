{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews, stopwords\n",
    "import random\n",
    "from nltk.probability import FreqDist\n",
    "# from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = []\n",
    "cat = movie_reviews.categories()\n",
    "\n",
    "for category in cat:\n",
    "    for fileid in movie_reviews.fileids(category):\n",
    "        document.append([movie_reviews.words(fileid), category])\n",
    "\n",
    "random.shuffle(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "701543"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = []\n",
    "stop_words = stopwords.words('english')\n",
    "for w in movie_reviews.words():\n",
    "        if w not in stop_words and w.isalpha():\n",
    "            all_words.append(w)\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "# nltk prob distribution is a dictionary with key values being the words and the values bing the freq \n",
    "\n",
    "#len(all_words)\n",
    "#print(type(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_most_frequent = []\n",
    "most_frequent = all_words.most_common(3000) # most frequent is a 2d list with first element being the word and the second the freq\n",
    "words_most_frequent = [word[0] for word in most_frequent]\n",
    "\n",
    "def feature_set(word_set):\n",
    "    features = {}\n",
    "    word_list= set(word_set)\n",
    "    for w in words_most_frequent:\n",
    "        features[w] = w in word_list\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg/cv000_29416.txt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileid = movie_reviews.fileids(movie_reviews.categories()[0])[0]\n",
    "fileid\n",
    "# print(feature_set(movie_reviews.words(fileid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "dtuples = ()\n",
    "for doc in document:\n",
    "    dtuples = (feature_set(doc[0]), doc[1])\n",
    "    features.append(dtuples)\n",
    "    \n",
    "# This is a featureset\n",
    "# A featureset of a movie_review file with some fileid is words followed by bollean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying the Naive Bayes classifier\n",
    "\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = features[:1900]\n",
    "testing = features[1900:]\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training) # takes featureset as a parameter\n",
    "\n",
    "accuracy = nltk.classify.accuracy(classifier, testing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "               ludicrous = True              neg : pos    =     10.8 : 1.0\n",
      "             outstanding = True              pos : neg    =     10.7 : 1.0\n",
      "                 idiotic = True              neg : pos    =      9.1 : 1.0\n",
      "                   mulan = True              pos : neg    =      8.9 : 1.0\n",
      "                  seagal = True              neg : pos    =      7.9 : 1.0\n",
      "                  finest = True              pos : neg    =      7.8 : 1.0\n",
      "            breathtaking = True              pos : neg    =      7.8 : 1.0\n",
      "              schumacher = True              neg : pos    =      6.7 : 1.0\n",
      "             wonderfully = True              pos : neg    =      6.4 : 1.0\n",
      "                   anger = True              pos : neg    =      6.4 : 1.0\n",
      "                religion = True              pos : neg    =      6.1 : 1.0\n",
      "                   jolie = True              neg : pos    =      5.8 : 1.0\n",
      "                   damon = True              pos : neg    =      5.6 : 1.0\n",
      "                   flynt = True              pos : neg    =      5.6 : 1.0\n",
      "                lebowski = True              pos : neg    =      5.6 : 1.0\n",
      "                 garbage = True              neg : pos    =      5.6 : 1.0\n",
      "                  wasted = True              neg : pos    =      5.5 : 1.0\n",
      "                   awful = True              neg : pos    =      5.3 : 1.0\n",
      "                  poorly = True              neg : pos    =      5.3 : 1.0\n",
      "                   waste = True              neg : pos    =      5.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can furtghur remove the Named entitites using pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pickle\n",
    "import pickle\n",
    "\n",
    "save_classifier = open(\"naivebayes.pickle\", \"wb\") # write in bytes\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_classifier = open(\"naivebayes.pickle\", \"rb\") # read in bytes\n",
    "classifier = pickle.load(open_classifier)\n",
    "open_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = nltk.classify.accuracy(classifier, testing)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn Classifier\n",
    "\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultinomialNB\n",
    "\n",
    "MultinomialNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MultinomialNB_classifier.train(training)\n",
    "\n",
    "# can also do MultinomialNB_classifier = SklearnClassifier(MultinomialNB()).train(training)\n",
    "\n",
    "accuracy = nltk.classify.accuracy(MultinomialNB_classifier, testing)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GaussianNB\n",
    "\n",
    "# GaussianNB_classifier = SklearnClassifier(GaussianNB()).train(training)\n",
    "\n",
    "# accuracy = nltk.classify.accuracy(GaussianNB_classifier, testing)\n",
    "# accuracy\n",
    "\n",
    "# This will result in an error\n",
    "# Gaussian needs a sparce matrix or known as a Confusion matrix, not a featureset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BernoulliNB\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB()).train(training)\n",
    "\n",
    "accuracy = nltk.classify.accuracy(BernoulliNB_classifier, testing)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arkom\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arkom\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arkom\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81\n"
     ]
    }
   ],
   "source": [
    "# Lets import some more models from sklearn\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC # Numeric svc\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression()).train(training)\n",
    "\n",
    "accuracy_LogisticRegression = nltk.classify.accuracy(LogisticRegression_classifier, testing)\n",
    "print(accuracy_LogisticRegression)\n",
    "\n",
    "\n",
    "# SGDClassifier\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier()).train(training)\n",
    "\n",
    "accuracy_SGDClassifier = nltk.classify.accuracy(SGDClassifier_classifier, testing)\n",
    "print(accuracy_SGDClassifier)\n",
    "\n",
    "\n",
    "# Svc Classifier\n",
    "\n",
    "SVC_classifier = SklearnClassifier(SVC()).train(training)\n",
    "\n",
    "accuracy_SVC_classifier = nltk.classify.accuracy(SVC_classifier, testing)\n",
    "print(accuracy_SVC_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC()).train(training)\n",
    "\n",
    "accuracy_LinearSVC_classifier = nltk.classify.accuracy(LinearSVC_classifier, testing)\n",
    "print(accuracy_LinearSVC_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87\n"
     ]
    }
   ],
   "source": [
    "# NuSVC\n",
    "\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC()).train(training)\n",
    "\n",
    "accuracy_NuSVC_classifier = nltk.classify.accuracy(NuSVC_classifier, testing)\n",
    "print(accuracy_NuSVC_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting\n",
    "\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mean, median, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
